{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-19T07:42:38.703136Z","iopub.execute_input":"2022-03-19T07:42:38.703637Z","iopub.status.idle":"2022-03-19T07:42:39.675167Z","shell.execute_reply.started":"2022-03-19T07:42:38.703604Z","shell.execute_reply":"2022-03-19T07:42:39.674148Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/data-science-job/data_science_job.csv\")\ndata","metadata":{"execution":{"iopub.status.busy":"2022-03-19T07:08:01.532629Z","iopub.execute_input":"2022-03-19T07:08:01.533107Z","iopub.status.idle":"2022-03-19T07:08:01.632233Z","shell.execute_reply.started":"2022-03-19T07:08:01.533070Z","shell.execute_reply":"2022-03-19T07:08:01.631324Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"data.shape\n","metadata":{"execution":{"iopub.status.busy":"2022-03-19T07:08:37.034053Z","iopub.execute_input":"2022-03-19T07:08:37.034307Z","iopub.status.idle":"2022-03-19T07:08:37.040200Z","shell.execute_reply.started":"2022-03-19T07:08:37.034280Z","shell.execute_reply":"2022-03-19T07:08:37.039195Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"data.info()","metadata":{"execution":{"iopub.status.busy":"2022-03-19T07:13:55.694306Z","iopub.execute_input":"2022-03-19T07:13:55.694563Z","iopub.status.idle":"2022-03-19T07:13:55.718397Z","shell.execute_reply.started":"2022-03-19T07:13:55.694536Z","shell.execute_reply":"2022-03-19T07:13:55.717550Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"#Check for total number of null values in each  variable/feature/column\ndata.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-03-19T07:13:39.066972Z","iopub.execute_input":"2022-03-19T07:13:39.067261Z","iopub.status.idle":"2022-03-19T07:13:39.081334Z","shell.execute_reply.started":"2022-03-19T07:13:39.067233Z","shell.execute_reply":"2022-03-19T07:13:39.080660Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"#Check for percentage of null values in each variable/feature/column\ndata.isnull().mean()*100","metadata":{"execution":{"iopub.status.busy":"2022-03-19T07:24:16.774108Z","iopub.execute_input":"2022-03-19T07:24:16.774381Z","iopub.status.idle":"2022-03-19T07:24:16.788774Z","shell.execute_reply.started":"2022-03-19T07:24:16.774348Z","shell.execute_reply":"2022-03-19T07:24:16.788237Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"**Complete Case Analysis**<br>\nIn this we dicard all the observation which has null values.<br>\nConsidering Constraints:<br>\n1. Null value of a column should be 5%<","metadata":{}},{"cell_type":"code","source":"#Get names of all the columns whose null value % <5% and >0%\ncol = [i for i in data.columns if data[i].isnull().mean()*100<5 and data[i].isnull().mean()*100>0 ]\ncol","metadata":{"execution":{"iopub.status.busy":"2022-03-19T07:25:20.695728Z","iopub.execute_input":"2022-03-19T07:25:20.696017Z","iopub.status.idle":"2022-03-19T07:25:20.718615Z","shell.execute_reply.started":"2022-03-19T07:25:20.695984Z","shell.execute_reply":"2022-03-19T07:25:20.717613Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"data[col].sample(5)","metadata":{"execution":{"iopub.status.busy":"2022-03-19T07:27:23.633084Z","iopub.execute_input":"2022-03-19T07:27:23.633522Z","iopub.status.idle":"2022-03-19T07:27:23.646733Z","shell.execute_reply.started":"2022-03-19T07:27:23.633468Z","shell.execute_reply":"2022-03-19T07:27:23.645984Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"#Applying CCA to all these columns and saving it to new dataframe to compare before and after results.\n\nnew_data = data[col].dropna()\nnew_data.isnull().sum() # 0 null values remained\n(new_data.shape[0]/data.shape[0])*100 # 89.68577095730244 % data remained from original\n\n    ","metadata":{"execution":{"iopub.status.busy":"2022-03-19T07:41:19.012112Z","iopub.execute_input":"2022-03-19T07:41:19.012610Z","iopub.status.idle":"2022-03-19T07:41:19.028149Z","shell.execute_reply.started":"2022-03-19T07:41:19.012578Z","shell.execute_reply":"2022-03-19T07:41:19.027229Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":"**Comparing Original vs Modified Data**","metadata":{}},{"cell_type":"markdown","source":"*Comparing Numerical Data*","metadata":{}},{"cell_type":"code","source":"#This will plot histogram at only numerical data of modified data\nnew_data.hist(bins=50, density=True, figsize=(12, 12))","metadata":{"execution":{"iopub.status.busy":"2022-03-19T07:37:03.370900Z","iopub.execute_input":"2022-03-19T07:37:03.371369Z","iopub.status.idle":"2022-03-19T07:37:03.379713Z","shell.execute_reply.started":"2022-03-19T07:37:03.371321Z","shell.execute_reply":"2022-03-19T07:37:03.378835Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"#This will plot histogram at only numerical data of Original data\ndata[col].hist(bins=50, density=True, figsize=(12, 12))","metadata":{"execution":{"iopub.status.busy":"2022-03-19T07:39:30.878068Z","iopub.execute_input":"2022-03-19T07:39:30.878667Z","iopub.status.idle":"2022-03-19T07:39:30.884458Z","shell.execute_reply.started":"2022-03-19T07:39:30.878618Z","shell.execute_reply":"2022-03-19T07:39:30.883717Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"#Compare city_development_index in single plot\nfig = plt.figure()\nax = fig.add_subplot(111)\n\n# original data\ndata['city_development_index'].hist(bins=50, ax=ax, density=True, color='red')\n\n# data after cca, the argument alpha makes the color transparent, so we can\n# see the overlay of the 2 distributions\nnew_data['city_development_index'].hist(bins=50, ax=ax, color='green', density=True, alpha=0.8)\n\n#As you can see from the plot the difference is minimal so CCA is acceptable","metadata":{"execution":{"iopub.status.busy":"2022-03-19T07:59:43.678827Z","iopub.execute_input":"2022-03-19T07:59:43.679124Z","iopub.status.idle":"2022-03-19T07:59:44.168450Z","shell.execute_reply.started":"2022-03-19T07:59:43.679091Z","shell.execute_reply":"2022-03-19T07:59:44.167615Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"#Compare experience in single plot\nfig = plt.figure()\nax = fig.add_subplot(111)\n\n#Original data\ndata[\"experience\"].hist(bins=50,ax=ax,density=True,color=\"red\")\n#Modified data\nnew_data[\"experience\"].hist(bins=50,ax=ax,density=True,color=\"green\",alpha=0.7)\n\n#As you can see from the plot the difference is minimal so CCA is acceptable","metadata":{"execution":{"iopub.status.busy":"2022-03-19T08:04:38.712807Z","iopub.execute_input":"2022-03-19T08:04:38.713087Z","iopub.status.idle":"2022-03-19T08:04:39.075808Z","shell.execute_reply.started":"2022-03-19T08:04:38.713058Z","shell.execute_reply":"2022-03-19T08:04:39.074990Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"#Compare training_hours in single plot\nfig = plt.figure()\nax = fig.add_subplot(111)\n\n#Original data\ndata[\"training_hours\"].hist(bins=50,ax=ax,density=True,color=\"red\")\n#Modified data\nnew_data[\"training_hours\"].hist(bins=50,ax=ax,density=True,color=\"green\",alpha=0.7)\n","metadata":{"execution":{"iopub.status.busy":"2022-03-19T08:06:54.192010Z","iopub.execute_input":"2022-03-19T08:06:54.192431Z","iopub.status.idle":"2022-03-19T08:06:54.571997Z","shell.execute_reply.started":"2022-03-19T08:06:54.192391Z","shell.execute_reply":"2022-03-19T08:06:54.570986Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"markdown","source":"*Compare Categorical Data*","metadata":{}},{"cell_type":"code","source":"#For this we'll check the percentage of occurance before and after\ntemp = pd.concat([\n            # percentage of observations per category, original data\n            data['enrolled_university'].value_counts() / len(data),\n\n            # percentage of observations per category, cca data\n            new_data['enrolled_university'].value_counts() / len(new_data)\n        ],\n        axis=1)\n\n# add column names\ntemp.columns = ['original', 'cca']\n\ntemp\n\n#So, there is not much of difference in percentage of occurance so CCA is acceptable","metadata":{"execution":{"iopub.status.busy":"2022-03-19T08:12:50.561615Z","iopub.execute_input":"2022-03-19T08:12:50.561911Z","iopub.status.idle":"2022-03-19T08:12:50.576296Z","shell.execute_reply.started":"2022-03-19T08:12:50.561877Z","shell.execute_reply":"2022-03-19T08:12:50.575435Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"#For this we'll check the percentage of occurance before and after\ntemp = pd.concat([\n            # percentage of observations per category, original data\n            data['education_level'].value_counts() / len(data),\n\n            # percentage of observations per category, cca data\n            new_data['education_level'].value_counts() / len(new_data)\n        ],\n        axis=1)\n\n# add column names\ntemp.columns = ['original', 'cca']\n\ntemp\n#So, there is not much of difference in percentage of occurance so CCA is acceptable","metadata":{"execution":{"iopub.status.busy":"2022-03-19T08:14:30.577774Z","iopub.execute_input":"2022-03-19T08:14:30.578095Z","iopub.status.idle":"2022-03-19T08:14:30.592907Z","shell.execute_reply.started":"2022-03-19T08:14:30.578063Z","shell.execute_reply":"2022-03-19T08:14:30.591993Z"},"trusted":true},"execution_count":63,"outputs":[]}]}